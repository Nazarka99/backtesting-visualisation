{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-30T20:33:18.956580Z",
     "start_time": "2024-08-30T20:32:41.952583700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 22:33:11,758 - INFO - Data for XRP/USDT on 2h saved/updated successfully.\n",
      "E:\\side projects\\backtesting&visualization\\common_functions.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['HA_open'].iloc[0] = (data['open'].iloc[0] + data['close'].iloc[0]) / 2\n",
      "2024-08-30 22:33:18,300 - INFO - Data for XRP/USDT on 4h saved/updated successfully.\n",
      "E:\\side projects\\backtesting&visualization\\common_functions.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['HA_open'].iloc[0] = (data['open'].iloc[0] + data['close'].iloc[0]) / 2\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_6268\\3357988480.py:45: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  higher_df = higher_df.resample('1T').ffill().reindex(df.index).ffill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Prediction for XRP/USDT on 2h timeframe: Win\n",
      "Last predictions saved to predictions_results.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\AR\\backtesting&visualization\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from _managing_data import update_data\n",
    "from common_functions import calculate_heikin_ashi\n",
    "import pandas_ta as ta\n",
    "import joblib\n",
    "\n",
    "# Helper function to determine the higher timeframe\n",
    "def get_higher_timeframe(timeframe):\n",
    "    if timeframe == '15m':\n",
    "        return '1h'\n",
    "    elif timeframe == '30m':\n",
    "        return '2h'\n",
    "    elif timeframe == '1h':\n",
    "        return '4h'\n",
    "    elif timeframe == '2h':\n",
    "        return '4h'\n",
    "    elif timeframe == '4h':\n",
    "        return '1d'  # Optional: adjust as necessary\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Calculate Kaufman Efficiency Ratio (KER)\n",
    "def calculate_kaufman_efficiency_ratio(data_series, period):\n",
    "    signal = data_series.diff(period).abs()\n",
    "    noise = data_series.diff().abs().rolling(window=period).sum()\n",
    "    ker = signal / noise\n",
    "    return ker\n",
    "\n",
    "# Calculate all necessary indicators\n",
    "def calculate_indicators(df):\n",
    "    df[['SUPERT', 'direction', 'long', 'short']] = ta.supertrend(df.HA_high, df.HA_low, df.HA_close, length=12, multiplier=3)\n",
    "    macd = ta.macd(df['HA_close'], fast=12, slow=26, signal=9)\n",
    "    df = pd.concat([df, macd], axis=1)\n",
    "    df['ATR'] = ta.atr(df['HA_high'], df['HA_low'], df['HA_close'], length=14)\n",
    "    df['RSI_7'] = ta.rsi(df['HA_close'], length=7)\n",
    "    df['RSI_14'] = ta.rsi(df['HA_close'], length=14)\n",
    "    df['RSI_21'] = ta.rsi(df['HA_close'], length=21)\n",
    "    df['KER_RSI_7'] = calculate_kaufman_efficiency_ratio(df['RSI_7'], period=10)\n",
    "    df['KER_RSI_14'] = calculate_kaufman_efficiency_ratio(df['RSI_14'], period=14)\n",
    "    df['KER_RSI_21'] = calculate_kaufman_efficiency_ratio(df['RSI_21'], period=20)\n",
    "    return df\n",
    "\n",
    "# Align higher timeframe data with the lower timeframe data\n",
    "def align_higher_timeframe_data(df, higher_df):\n",
    "    higher_df = higher_df.resample('1T').ffill().reindex(df.index).ffill()\n",
    "    return higher_df\n",
    "\n",
    "# Generate signals\n",
    "def generate_signals(df):\n",
    "    df['Type_encoded'] = None  # Initialize the column with None\n",
    "    df.loc[((df['MACD_12_26_9'].shift(1) < df['MACDs_12_26_9'].shift(1)) &\n",
    "            (df['MACD_12_26_9'] > df['MACDs_12_26_9']) &\n",
    "            (df['SUPERT'] > df['HA_close'])), 'Type_encoded'] = 0  # Long Signal\n",
    "\n",
    "    df.loc[((df['MACD_12_26_9'].shift(1) > df['MACDs_12_26_9'].shift(1)) &\n",
    "            (df['MACD_12_26_9'] < df['MACDs_12_26_9']) &\n",
    "            (df['SUPERT'] < df['HA_close'])), 'Type_encoded'] = 1  # Short Signal\n",
    "    return df\n",
    "\n",
    "# Load the trained model\n",
    "model_filename = 'random_forest_model_v1.0.pkl'\n",
    "rf_classifier = joblib.load(model_filename)\n",
    "\n",
    "# Main process\n",
    "if __name__ == \"__main__\":\n",
    "    # Dictionary with symbols and their corresponding timeframes\n",
    "    # symbols_timeframes = {\n",
    "    #     'LINK/USDT': ['30m'],\n",
    "    #     'BNB/USDT': ['30m'],\n",
    "    #     'DOGE/USDT': ['30m'],\n",
    "    #     'XRP/USDT': ['15m']\n",
    "    # }\n",
    "\n",
    "    symbols_timeframes = {\n",
    "        'XRP/USDT': ['2h']\n",
    "    }\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Encoding mappings\n",
    "    symbol_mapping = {\n",
    "        'BTC/USDT': 0, 'ETH/USDT': 1, 'BNB/USDT': 2, 'SOL/USDT': 3, 'XRP/USDT': 4,\n",
    "        'ADA/USDT': 5, 'DOGE/USDT': 6, 'MATIC/USDT': 7, 'DOT/USDT': 8, 'LINK/USDT': 9,\n",
    "        'IMX/USDT': 10, 'ICP/USDT': 11\n",
    "    }\n",
    "    timeframe_mapping = {\n",
    "        '15m': 0, '30m': 1, '1h': 2, '2h': 3, '4h': 4\n",
    "    }\n",
    "\n",
    "    for symbol, timeframes in symbols_timeframes.items():\n",
    "        for timeframe in timeframes:\n",
    "            # Fetch and process data for the lower timeframe\n",
    "            df = update_data(symbol, timeframe)\n",
    "            df = calculate_heikin_ashi(df)\n",
    "\n",
    "            # Fetch and process data for the higher timeframe\n",
    "            higher_timeframe = get_higher_timeframe(timeframe)\n",
    "            if higher_timeframe:\n",
    "                higher_df = update_data(symbol, higher_timeframe)\n",
    "                higher_df = calculate_heikin_ashi(higher_df)\n",
    "                higher_df = calculate_indicators(higher_df)\n",
    "                higher_df = align_higher_timeframe_data(df, higher_df)\n",
    "\n",
    "                # Calculate indicators and generate signals for the lower timeframe\n",
    "                df = calculate_indicators(df)\n",
    "                df = generate_signals(df)\n",
    "\n",
    "                # Create a DataFrame to store signals with all required columns\n",
    "                signals_df = pd.DataFrame({\n",
    "                    'Symbol_encoded': symbol_mapping[symbol],\n",
    "                    'Timeframe_encoded': timeframe_mapping[timeframe],\n",
    "                    'Type_encoded': df['Type_encoded'],\n",
    "                    'RSI_7': df['RSI_7'],\n",
    "                    'RSI_14': df['RSI_14'],\n",
    "                    'RSI_21': df['RSI_21'],\n",
    "                    'KER_RSI_7': df['KER_RSI_7'],\n",
    "                    'KER_RSI_14': df['KER_RSI_14'],\n",
    "                    'KER_RSI_21': df['KER_RSI_21'],\n",
    "                    'MACD_Line': df['MACD_12_26_9'],\n",
    "                    'Signal_Line': df['MACDs_12_26_9'],\n",
    "                    'MACD_Histogram': df['MACDh_12_26_9'],\n",
    "                    'Higher_RSI_7': higher_df['RSI_7'],\n",
    "                    'Higher_RSI_14': higher_df['RSI_14'],\n",
    "                    'Higher_RSI_21': higher_df['RSI_21'],\n",
    "                    'Higher_KER_RSI_7': higher_df['KER_RSI_7'],\n",
    "                    'Higher_KER_RSI_14': higher_df['KER_RSI_14'],\n",
    "                    'Higher_KER_RSI_21': higher_df['KER_RSI_21'],\n",
    "                    'Higher_MACD_Line': higher_df['MACD_12_26_9'],\n",
    "                    'Higher_Signal_Line': higher_df['MACDs_12_26_9'],\n",
    "                    'Higher_MACD_Histogram': higher_df['MACDh_12_26_9']\n",
    "                })\n",
    "\n",
    "                # Filter only rows where a signal was generated\n",
    "                signals_df = signals_df.dropna(subset=['Type_encoded'])\n",
    "\n",
    "                # Predict for the last signal generated\n",
    "                if not signals_df.empty:\n",
    "                    last_signal = signals_df.iloc[-1]  # Select the last signal\n",
    "                    features = last_signal.values.reshape(1, -1)\n",
    "                    prediction = rf_classifier.predict(features)[0]\n",
    "                    result = 'Win' if prediction == 1 else 'Loss'\n",
    "                    predictions.append({\n",
    "                        'Time': last_signal.name,\n",
    "                        'Symbol': symbol,\n",
    "                        'Timeframe': timeframe,\n",
    "                        'Type': 'Long' if last_signal['Type_encoded'] == 0 else 'Short',\n",
    "                        'Predicted_Result': result\n",
    "                    })\n",
    "                    # Print last prediction\n",
    "                    print(f\"Last Prediction for {symbol} on {timeframe} timeframe: {result}\")\n",
    "\n",
    "    # Convert predictions to DataFrame and save to Excel\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    predictions_df.to_excel('predictions_results.xlsx', index=False)\n",
    "    print(\"Last predictions saved to predictions_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
